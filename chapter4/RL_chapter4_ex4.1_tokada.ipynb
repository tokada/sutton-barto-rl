{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 例4.1「格子世界」（図4.2）\n",
    "\n",
    "反復方策評価の実装を行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "class GridWorld:\n",
    "    \"\"\"格子世界を定義するクラス\"\"\"\n",
    "    \n",
    "    # 定数定義\n",
    "    ACTIONS = [\"up\", \"down\", \"right\", \"left\"] # 可能なアクションの定義\n",
    "    REWARD = -1.0  # 期待報酬関数（任意のs,s',aに対して-1とする）\n",
    "    PRINTABLE_ITERATIONS = [0, 1, 2, 3, 10] # 出力する回\n",
    "    THETA = 0.0001 # 停止判定基準の値（正の小さな値）\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"コンストラクタ\"\"\"\n",
    "        \n",
    "        # ラベルごと、アクションごとの状態遷移先を定義\n",
    "        self.transitions = {\n",
    "             1: { \"up\": 1 , \"down\": 5 , \"right\": 2 , \"left\": 0 },\n",
    "             2: { \"up\": 2 , \"down\": 6 , \"right\": 3 , \"left\": 1 },\n",
    "             3: { \"up\": 3 , \"down\": 7 , \"right\": 3 , \"left\": 2 },\n",
    "             4: { \"up\": 0 , \"down\": 8 , \"right\": 5 , \"left\": 4 },\n",
    "             5: { \"up\": 1 , \"down\": 9 , \"right\": 6 , \"left\": 4 },\n",
    "             6: { \"up\": 2 , \"down\": 10, \"right\": 7 , \"left\": 5 },\n",
    "             7: { \"up\": 3 , \"down\": 11, \"right\": 7 , \"left\": 6 },\n",
    "             8: { \"up\": 4 , \"down\": 12, \"right\": 9 , \"left\": 8 },\n",
    "             9: { \"up\": 5 , \"down\": 13, \"right\": 10, \"left\": 8 },\n",
    "            10: { \"up\": 6 , \"down\": 14, \"right\": 11, \"left\": 9 },\n",
    "            11: { \"up\": 7 , \"down\": 0 , \"right\": 11, \"left\": 10 },\n",
    "            12: { \"up\": 8 , \"down\": 12, \"right\": 13, \"left\": 12 },\n",
    "            13: { \"up\": 9 , \"down\": 13, \"right\": 14, \"left\": 12 },\n",
    "            14: { \"up\": 10, \"down\": 14, \"right\": 0 , \"left\": 13 },\n",
    "        }\n",
    "    \n",
    "    def expected_reward(self, s_from, s_to, action):\n",
    "        \"\"\"期待報酬関数\"\"\"\n",
    "        return self.REWARD # すべて「-1」\n",
    "\n",
    "    def initialize_v(self):\n",
    "        \"\"\"状態価値ベクトルを初期化する\"\"\"\n",
    "        self.values = np.array([0.0 for i in range(16)])\n",
    "\n",
    "    def print_v(self, values, shaped=True):\n",
    "        \"\"\"状態価値ベクトルを出力する\"\"\"\n",
    "        if shaped:\n",
    "            print(np.round(np.reshape(values, (4, 4)), 1))\n",
    "        else:\n",
    "            print(np.round(values), 1)\n",
    "\n",
    "    def policy_evaluation(self, values, sweep=False):\n",
    "        \"\"\"方策評価のアルゴリズム実装\"\"\"\n",
    "        old_values = copy.copy(values) # 元の価値\n",
    "        new_values = copy.copy(values) # 新しい価値\n",
    "        for i in self.transitions.keys(): # 終端(0と15)は更新しない\n",
    "            reward_sum = 0.0\n",
    "            for a in self.ACTIONS:\n",
    "                # アクションごとに、報酬値として-1に遷移先の状態価値を足し込む\n",
    "                reward_sum += self.expected_reward(i, self.transitions[i][a], a) + old_values[self.transitions[i][a]]\n",
    "            # 状態価値を更新\n",
    "            new_values[i] = 0.25 * reward_sum # 特定のアクションをとる確率0.25を掛け、報酬の期待値を得る\n",
    "            if sweep:\n",
    "                old_values[i] = new_values[i] # その場更新する場合\n",
    "        return new_values\n",
    "\n",
    "    def run_iterative_policy_evaluation(self, sweep=False, max=None, shaped=True):\n",
    "        \"\"\"反復方策評価のアルゴリズム実装\"\"\"\n",
    "        # 評価対象の方策πを入力\n",
    "        # 状態価値ベクトルを初期化する\n",
    "        self.initialize_v()\n",
    "        if 0 in self.PRINTABLE_ITERATIONS:\n",
    "            print(\"## 初期値:\")\n",
    "            self.print_v(self.values, shaped) # 初期値を出力\n",
    "        k = 1\n",
    "        delta = 0.0\n",
    "        while True:\n",
    "            old_values = copy.copy(self.values)\n",
    "            self.values = self.policy_evaluation(old_values, sweep)\n",
    "            if k in self.PRINTABLE_ITERATIONS:\n",
    "                print(\"## %d回目:\" % k)\n",
    "                self.print_v(self.values, shaped) # k回目の更新値を出力\n",
    "            k += 1\n",
    "            if max is None:\n",
    "                # maxが指定されていない場合は、deltaが停止判定基準になるまで実行する\n",
    "                delta = np.max(np.absolute(self.values - old_values))\n",
    "                if delta < self.THETA:\n",
    "                    print(\"## %d回目（収束）:\" % k)\n",
    "                    self.print_v(self.values, shaped) # 収束回の更新値を出力\n",
    "                    break\n",
    "            if max is not None and k > max:\n",
    "                # maxが指定されている場合は、max回まで実行する\n",
    "                break\n",
    "        return self.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# スイープ操作（その場更新）しない場合:\n",
      "## 初期値:\n",
      "[[ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]]\n",
      "## 1回目:\n",
      "[[ 0. -1. -1. -1.]\n",
      " [-1. -1. -1. -1.]\n",
      " [-1. -1. -1. -1.]\n",
      " [-1. -1. -1.  0.]]\n",
      "## 2回目:\n",
      "[[ 0.  -1.8 -2.  -2. ]\n",
      " [-1.8 -2.  -2.  -2. ]\n",
      " [-2.  -2.  -2.  -1.8]\n",
      " [-2.  -2.  -1.8  0. ]]\n",
      "## 3回目:\n",
      "[[ 0.  -2.4 -2.9 -3. ]\n",
      " [-2.4 -2.9 -3.  -2.9]\n",
      " [-2.9 -3.  -2.9 -2.4]\n",
      " [-3.  -2.9 -2.4  0. ]]\n",
      "## 10回目:\n",
      "[[ 0.  -6.1 -8.4 -9. ]\n",
      " [-6.1 -7.7 -8.4 -8.4]\n",
      " [-8.4 -8.4 -7.7 -6.1]\n",
      " [-9.  -8.4 -6.1  0. ]]\n",
      "## 174回目（収束）:\n",
      "[[  0. -14. -20. -22.]\n",
      " [-14. -18. -20. -20.]\n",
      " [-20. -20. -18. -14.]\n",
      " [-22. -20. -14.   0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  0.        , -13.99893866, -19.99842728, -21.99824003,\n",
       "       -13.99893866, -17.99861452, -19.9984378 , -19.99842728,\n",
       "       -19.99842728, -19.9984378 , -17.99861452, -13.99893866,\n",
       "       -21.99824003, -19.99842728, -13.99893866,   0.        ])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 実行プログラム\n",
    "gw = GridWorld()\n",
    "\n",
    "print('# スイープ操作（その場更新）しない場合:')\n",
    "gw.run_iterative_policy_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# スイープ操作（その場更新）する場合:\n",
      "## 初期値:\n",
      "[[ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]]\n",
      "## 1回目:\n",
      "[[ 0.  -1.  -1.2 -1.3]\n",
      " [-1.  -1.5 -1.7 -1.8]\n",
      " [-1.2 -1.7 -1.8 -1.9]\n",
      " [-1.3 -1.8 -1.9  0. ]]\n",
      "## 2回目:\n",
      "[[ 0.  -1.9 -2.5 -2.7]\n",
      " [-1.9 -2.8 -3.2 -3.4]\n",
      " [-2.5 -3.2 -3.6 -3.2]\n",
      " [-2.7 -3.4 -3.2  0. ]]\n",
      "## 3回目:\n",
      "[[ 0.  -2.8 -3.8 -4.2]\n",
      " [-2.8 -4.  -4.7 -4.9]\n",
      " [-3.8 -4.7 -5.  -4.3]\n",
      " [-4.2 -4.9 -4.3  0. ]]\n",
      "## 10回目:\n",
      "[[  0.   -7.8 -11.1 -12.2]\n",
      " [ -7.8 -10.4 -11.8 -11.9]\n",
      " [-11.1 -11.8 -11.1  -8.8]\n",
      " [-12.2 -11.9  -8.8   0. ]]\n",
      "## 115回目（収束）:\n",
      "[[  0. -14. -20. -22.]\n",
      " [-14. -18. -20. -20.]\n",
      " [-20. -20. -18. -14.]\n",
      " [-22. -20. -14.   0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  0.        , -13.99931242, -19.99901152, -21.99891199,\n",
       "       -13.99931242, -17.99915625, -19.99908389, -19.99909436,\n",
       "       -19.99901152, -19.99908389, -17.99922697, -13.99942284,\n",
       "       -21.99891199, -19.99909436, -13.99942284,   0.        ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('# スイープ操作（その場更新）する場合:')\n",
    "gw.run_iterative_policy_evaluation(sweep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 練習問題4.1\n",
    "\n",
    "$Q^\\pi(s,a)=\\sum_{s'}^{}{R^a_{s,s'}P^a_{s,s'}}+\\gamma\\sum_{s'}^{}{P^a_{s,s'}V^\\pi(s')}$ \n",
    "\n",
    "under policy $\\pi$, any $R=-1, \\gamma=0.9$\n",
    "\n",
    "$Q^{\\pi}(11,down) = R^{down}_{11,0}P^{down}_{11,0}+{\\gamma}P^{down}_{11,0}V^\\pi(0) = -1\\times1+0.9\\times1\\times0 = -1$\n",
    "\n",
    "$Q^{\\pi}(7,down) = R^{down}_{7,11}P^{down}_{7,11}+{\\gamma}P^{down}_{7,11}V^\\pi(11) = -1\\times1+0.9\\times1\\times-14 = -13.6$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 練習問題4.2\n",
    "\n",
    "状態13の真下に新しい状態15を追加し、状態15で行動→状態が down→15, left→12, right→14, up→13 へ遷移するものとした場合の $V^\\pi(15)$ を計算する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'down': 5, 'left': 0, 'right': 2, 'up': 1},\n",
       " 2: {'down': 6, 'left': 1, 'right': 3, 'up': 2},\n",
       " 3: {'down': 7, 'left': 2, 'right': 3, 'up': 3},\n",
       " 4: {'down': 8, 'left': 4, 'right': 5, 'up': 0},\n",
       " 5: {'down': 9, 'left': 4, 'right': 6, 'up': 1},\n",
       " 6: {'down': 10, 'left': 5, 'right': 7, 'up': 2},\n",
       " 7: {'down': 11, 'left': 6, 'right': 7, 'up': 3},\n",
       " 8: {'down': 12, 'left': 8, 'right': 9, 'up': 4},\n",
       " 9: {'down': 13, 'left': 8, 'right': 10, 'up': 5},\n",
       " 10: {'down': 14, 'left': 9, 'right': 11, 'up': 6},\n",
       " 11: {'down': 0, 'left': 10, 'right': 11, 'up': 7},\n",
       " 12: {'down': 12, 'left': 12, 'right': 13, 'up': 8},\n",
       " 13: {'down': 13, 'left': 12, 'right': 14, 'up': 9},\n",
       " 14: {'down': 14, 'left': 13, 'right': 0, 'up': 10},\n",
       " 15: {'down': 15, 'left': 12, 'right': 14, 'up': 13}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gw2 = GridWorld()\n",
    "gw2.transitions[15] = {'down': 15, 'left': 12, 'right': 14, 'up': 13}\n",
    "gw2.transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 初期値:\n",
      "[[ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]]\n",
      "## 1回目:\n",
      "[[ 0.  -1.  -1.2 -1.3]\n",
      " [-1.  -1.5 -1.7 -1.8]\n",
      " [-1.2 -1.7 -1.8 -1.9]\n",
      " [-1.3 -1.8 -1.9 -2.2]]\n",
      "## 2回目:\n",
      "[[ 0.  -1.9 -2.5 -2.7]\n",
      " [-1.9 -2.8 -3.2 -3.4]\n",
      " [-2.5 -3.2 -3.6 -3.2]\n",
      " [-2.7 -3.4 -3.2 -3.9]]\n",
      "## 3回目:\n",
      "[[ 0.  -2.8 -3.8 -4.2]\n",
      " [-2.8 -4.  -4.7 -4.9]\n",
      " [-3.8 -4.7 -5.  -4.3]\n",
      " [-4.2 -4.9 -4.3 -5.3]]\n",
      "## 10回目:\n",
      "[[  0.   -7.8 -11.1 -12.2]\n",
      " [ -7.8 -10.4 -11.8 -11.9]\n",
      " [-11.1 -11.8 -11.1  -8.8]\n",
      " [-12.2 -11.9  -8.8 -12.1]]\n",
      "## 115回目（収束）:\n",
      "[[  0. -14. -20. -22.]\n",
      " [-14. -18. -20. -20.]\n",
      " [-20. -20. -18. -14.]\n",
      " [-22. -20. -14. -20.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  0.        , -13.99931242, -19.99901152, -21.99891199,\n",
       "       -13.99931242, -17.99915625, -19.99908389, -19.99909436,\n",
       "       -19.99901152, -19.99908389, -17.99922697, -13.99942284,\n",
       "       -21.99891199, -19.99909436, -13.99942284, -19.99911612])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gw2.run_iterative_policy_evaluation(sweep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上により、 $V^\\pi(15)=-20$ となる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "さらに、状態13での行動downが、新しい状態15に遷移するようにダイナミクスが変化した場合の $V^\\pi(15)$ を計算する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'down': 5, 'left': 0, 'right': 2, 'up': 1},\n",
       " 2: {'down': 6, 'left': 1, 'right': 3, 'up': 2},\n",
       " 3: {'down': 7, 'left': 2, 'right': 3, 'up': 3},\n",
       " 4: {'down': 8, 'left': 4, 'right': 5, 'up': 0},\n",
       " 5: {'down': 9, 'left': 4, 'right': 6, 'up': 1},\n",
       " 6: {'down': 10, 'left': 5, 'right': 7, 'up': 2},\n",
       " 7: {'down': 11, 'left': 6, 'right': 7, 'up': 3},\n",
       " 8: {'down': 12, 'left': 8, 'right': 9, 'up': 4},\n",
       " 9: {'down': 13, 'left': 8, 'right': 10, 'up': 5},\n",
       " 10: {'down': 14, 'left': 9, 'right': 11, 'up': 6},\n",
       " 11: {'down': 0, 'left': 10, 'right': 11, 'up': 7},\n",
       " 12: {'down': 12, 'left': 12, 'right': 13, 'up': 8},\n",
       " 13: {'down': 15, 'left': 12, 'right': 14, 'up': 9},\n",
       " 14: {'down': 14, 'left': 13, 'right': 0, 'up': 10},\n",
       " 15: {'down': 15, 'left': 12, 'right': 14, 'up': 13}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gw3 = GridWorld()\n",
    "gw3.transitions = copy.copy(gw2.transitions)\n",
    "gw3.transitions[13]['down'] = 15\n",
    "gw3.transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 初期値:\n",
      "[[ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]]\n",
      "## 1回目:\n",
      "[[ 0.  -1.  -1.2 -1.3]\n",
      " [-1.  -1.5 -1.7 -1.8]\n",
      " [-1.2 -1.7 -1.8 -1.9]\n",
      " [-1.3 -1.8 -1.9 -2.2]]\n",
      "## 2回目:\n",
      "[[ 0.  -1.9 -2.5 -2.7]\n",
      " [-1.9 -2.8 -3.2 -3.4]\n",
      " [-2.5 -3.2 -3.6 -3.2]\n",
      " [-2.7 -3.5 -3.2 -3.9]]\n",
      "## 3回目:\n",
      "[[ 0.  -2.8 -3.8 -4.2]\n",
      " [-2.8 -4.  -4.7 -4.9]\n",
      " [-3.8 -4.7 -5.  -4.3]\n",
      " [-4.2 -5.  -4.3 -5.4]]\n",
      "## 10回目:\n",
      "[[  0.   -7.8 -11.1 -12.2]\n",
      " [ -7.9 -10.5 -11.8 -11.9]\n",
      " [-11.2 -11.8 -11.1  -8.8]\n",
      " [-12.3 -12.   -8.9 -12.2]]\n",
      "## 115回目（収束）:\n",
      "[[  0. -14. -20. -22.]\n",
      " [-14. -18. -20. -20.]\n",
      " [-20. -20. -18. -14.]\n",
      " [-22. -20. -14. -20.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  0.        , -13.9993636 , -19.99908399, -21.99899095,\n",
       "       -13.99936685, -17.99922185, -19.99915318, -19.9991615 ,\n",
       "       -19.99909265, -19.99915945, -17.99928843, -13.99946691,\n",
       "       -21.99900476, -19.99917652, -13.99947208, -19.99919296])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gw3.run_iterative_policy_evaluation(sweep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上により、やはり $V^\\pi(15)=-20$ となる。"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
